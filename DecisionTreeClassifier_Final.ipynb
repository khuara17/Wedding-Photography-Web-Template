{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,csv\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tweets(filename, header = None):\n",
    "    #import data from csv file via pandas library\n",
    "    tweet_dataset = pd.read_csv(filename, encoding = 'ISO-8859-1', header = header)\n",
    "    tweet_dataset.columns = ['sentiment','id','date','flag','user','text']\n",
    "    #delete 3 columns: flags,id,user, as they are not required for analysis\n",
    "    for i in ['flag','id','user','date']: del tweet_dataset[i] # or tweet_dataset = tweet_dataset.drop([\"id\",\"user\",\"date\",\"user\"], axis = 1)\n",
    "    #in dataset, positive = 4, negative = 0; So change positive to 1\n",
    "    tweet_dataset.sentiment = tweet_dataset.sentiment.replace(4,1)\n",
    "    return tweet_dataset\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "        #Preprocess the text in a single tweet\n",
    "        #arguments: tweet = a single tweet in form of string \n",
    "        #convert the tweet to lower case\n",
    "        tweet.lower()\n",
    "        #convert all urls to sting \"URL\"\n",
    "        tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "        #convert all @username to \"AT_USER\"\n",
    "        tweet = re.sub('@[^\\s]+','AT_USER', tweet)\n",
    "        #correct all multiple white spaces to a single white space\n",
    "        tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "        #convert \"#topic\" to just \"topic\"\n",
    "        tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "        return tweet\n",
    "    \n",
    "def analysis(user_ip):\n",
    "    ip = preprocess_tweet(user_ip)\n",
    "    ip = np.array([user_ip])\n",
    "    vector = tfv.transform(ip)\n",
    "    sentiment = classifier.predict(vector)\n",
    "    if(sentiment == 0):\n",
    "        print(\"The Sentence is NEGATIVE\")\n",
    "    else:\n",
    "        print(\"The Sentence is POSITIVE\")    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing csv file\n",
    "#tweet_dataset = import_tweets(\"book1.csv\")\n",
    "tweet_dataset = import_tweets(\"training.1600000.processed.noemoticon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing and labeling\n",
    "tweet_dataset['text'] = tweet_dataset['text'].apply(preprocess_tweet)\n",
    "data = np.array(tweet_dataset['text'])\n",
    "label = np.array(tweet_dataset.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer(sublinear_tf=True, stop_words = \"english\") # we need to give proper stopwords list for better performance\n",
    "features = tfv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "    \n",
    "#fit model to data\n",
    "classifier = model.fit(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_classifier = open('Naive_bayes.pickle','wb')\n",
    "pickle.dump(classifier, open_classifier)\n",
    "open_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_classifier = open('Naive_bayes.pickle','rb')\n",
    "classifier_n = pickle.load(load_classifier)\n",
    "load_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796553125\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier_n.predict(X_test)\n",
    "#print(predictions)\n",
    "score = classifier_n.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796553125\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "#print(predictions)\n",
    "score = model.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the sentence :exactly after 30-32 days, mic problem, in-line mic not working, and when connected headphones it automatically mutes all volume by reducing audio levels automatically, tested on different mobile phones, problem not solved. Microphone either works or speakers. cannot use headphones for calling purpose. Your voice is not delivered to other end with this headphones. Now I don't have option for replacement or return. Obviously the seller will tell me to go to BoAt service center which is in mumbai city as shows google map and I live in Pune city. Very bad experience, my all money is wasted by this BoAt brand, I should have bought Audio Technica or scullcandy branded headphones in this same price segment. Utterly disappointing.\n",
      "The Sentence is NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "#checking on user data            \n",
    "n = input(\"enter the sentence :\")\n",
    "analysis(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pmd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228915662650602\n",
      "enter the sentence :I don't shopping often and I never Signed for Prime membership and was surprised to see being charged $8.39. I had never even opened to see what they offer. How I became a member? I had to unsubscribe. People be aware.\n",
      "The Sentence is NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#     #importing csv file\n",
    "#     tweet_dataset = import_tweets(\"book1.csv\")\n",
    "    \n",
    "#     #preprocessing and labeling\n",
    "#     tweet_dataset['text'] = tweet_dataset['text'].apply(preprocess_tweet)\n",
    "#     data = np.array(tweet_dataset['text'])\n",
    "#     label = np.array(tweet_dataset.sentiment)\n",
    "    \n",
    "#     #features extraction\n",
    "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#     tfv = TfidfVectorizer(sublinear_tf=True, stop_words = \"english\") # we need to give proper stopwords list for better performance\n",
    "#     features = tfv.fit_transform(data)\n",
    "    \n",
    "#     #features = feature_extraction(data, method = \"tfidf\") #1600000x288571 sparse matrix of type 'numpy.float64\n",
    "    \n",
    "#     #spliting data for training and testing\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2)\n",
    "    \n",
    "#     #training the model\n",
    "#     #model = train_classifier(X_train, y_train, X_test, y_test, \"logistic_regression\")\n",
    "    \n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     model = LogisticRegression(C=1.)\n",
    "    \n",
    "#     #fit model to data\n",
    "#     classifier = model.fit(features, label)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     #print(predictions)\n",
    "#     score = model.score(X_test, y_test)\n",
    "#     print(score)\n",
    "    \n",
    "#     #checking on user data            \n",
    "#     n = input(\"enter the sentence :\")\n",
    "#     analysis(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
